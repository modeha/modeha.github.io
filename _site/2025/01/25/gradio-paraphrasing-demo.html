<!DOCTYPE html>
<html lang="en"><head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Deep Learning" /></head>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<style>@import url(/public/css/syntax/monokai.css);</style>
  <title>Deep Learning</title>
  <!-- <link href="/public/css/bootstrap.min.css" rel="stylesheet"> -->

  <link href="/public/css/style.css" rel="stylesheet">
  <body>
  	<div class="container"> 
		<div class="sidebar">
			<div class="sidebar-item sidebar-header">
	<div class='sidebar-brand'>
		<a href="/about/">Deep Learning</a>
	</div>
	<p class="lead">A blog exploring deep learning, AI, and data science topics by Mohsen Dehghani.</p></div>

<div class="sidebar-item sidebar-nav">
	<ul class="nav">
      <li class="nav-title">Pages</li>
	  <li>
	  	<a class="nav-item" href="/">Articles</a>
	  </li>
	  
	  
	    
	  
	    
	      
	        <li>
	        	<a class="nav-item" href="/about/">
	            	About
	            </a>
	        </li>
	      
	    
	  
	    
	      
	    
	  
	    
	  
	    
	  
	    
	  
	</ul>
</div>

<div class="sidebar-item sidebar-nav">
  	<ul class="nav">
			<li class="nav-title">Categories</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#Update">
				<span class="name">Update</span>
				<span class="badge">13</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#Jekyll">
				<span class="name">Jekyll</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#update">
				<span class="name">update</span>
				<span class="badge">6</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#math">
				<span class="name">math</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#data-science">
				<span class="name">data-science</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	  </nav>
	</ul>
</div>

<div class="sidebar-item sidebar-footer">
	<p>Powered by <a href="https://github.com/jekyll/jekyll">Jekyll</a></p>
</div>
		</div>
		<div class="content">
			<article class="post">
	<header class="post-header">
		<div class="post-title"> 
			Gradio Paraphrasing Demo
		</div>
		<time class="post-date dt-published" datetime="2025-01-25T13:10:00-05:00" itemprop="datePublished">2025/01/25
		</time>		
	</header>

	<div class="post-content">
		<h2 id="paraphrasing-text-with-t5-model-using-gradio">Paraphrasing Text with T5 Model Using Gradio</h2>

<p>Paraphrasing is a crucial task in natural language processing (NLP) that involves rephrasing text while retaining its original meaning. It has numerous applications, such as content generation, text simplification, and improving readability. In this post, we will demonstrate how to build a simple yet effective paraphrasing tool using the T5 (Text-to-Text Transfer Transformer) model, fine-tuned on the PAWS (Paraphrase Adversaries from Word Scrambling) dataset.</p>

<p>We’ll leverage the <strong>Hugging Face Transformers</strong> library to load a pre-trained T5 model and the <strong>Gradio</strong> library to create an interactive web-based interface that allows users to input text and generate multiple paraphrased outputs. Gradio provides an intuitive and user-friendly way to deploy machine learning models with minimal effort.</p>

<h3 id="key-features-of-the-paraphrasing-tool">Key Features of the Paraphrasing Tool</h3>
<ul>
  <li><strong>Model</strong>: We use the <code class="highlighter-rouge">Vamsi/T5_Paraphrase_Paws</code> model, fine-tuned to generate high-quality paraphrases.</li>
  <li><strong>Input</strong>: Users can enter text into a textbox to be paraphrased.</li>
  <li><strong>Output</strong>: The tool generates multiple paraphrased versions of the input text.</li>
  <li><strong>Customization Options</strong>: Users can adjust the number of paraphrases and beam search size to fine-tune the results.</li>
</ul>

<h3 id="how-it-works">How It Works</h3>
<ol>
  <li>The input text is tokenized and processed using the pre-trained T5 tokenizer.</li>
  <li>The model generates paraphrased outputs by applying beam search, allowing the user to control the number of generated sequences.</li>
  <li>The results are displayed in a user-friendly interface powered by Gradio.</li>
  <li>Example inputs are provided to help users explore the tool’s capabilities.</li>
</ol>

<p>Below is the implementation of the paraphrasing tool as well you can try it yourself:</p>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">torch</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">sentencepiece</span> <span class="n">protobuf</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="n">gr</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="c1"># Load the tokenizer and model
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">paraphrase_text</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># Preprocess the text
</span>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"paraphrase: "</span> <span class="o">+</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># Generate paraphrased versions
</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
        <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
        <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="c1"># Decode the generated sequences
</span>    <span class="n">paraphrased_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">paraphrased_texts</span>

<span class="n">title</span> <span class="o">=</span> <span class="s">"Paraphrasing with T5 Model"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s">"This demo uses the T5 model fine-tuned on PAWS for generating paraphrases of input text. Simply enter your text and click 'Submit' to generate multiple paraphrased versions."</span>
<span class="n">article</span> <span class="o">=</span> <span class="s">"&lt;p style='text-align: center'&gt;&lt;a href='https://huggingface.co/Vamsi/T5_Paraphrase_Paws'&gt;Hugging Face Model&lt;/a&gt; | &lt;a href='https://github.com/huggingface/transformers'&gt;Transformers Library&lt;/a&gt;&lt;/p&gt;"</span>

<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">"Intelligence Analyst Trainer - 24-968-08-086 All information required to determine suitability for employment with the Canadian Security Intelligence Service is collected under the authority of the Canadian Security Intelligence Service Act."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The Privacy Act allows candidates to review collected information and request amendments."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Machine learning models are improving rapidly, and their applications are expanding across different industries."</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">iface</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">paraphrase_text</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">lines</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s">"Enter text to paraphrase here..."</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Number of paraphrases"</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Beam search size"</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s">"Paraphrased Outputs"</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">,</span>
    <span class="n">examples</span><span class="o">=</span><span class="n">examples</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># iface.launch(debug=True)
</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are using the default legacy behaviour of the &lt;class 'transformers.models.t5.tokenization_t5.T5Tokenizer'&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
c:\Users\mohse\.conda\envs\cdo_idp\lib\site-packages\torchvision\io\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\Users\mohse\.conda\envs\cdo_idp\Lib\site-packages\torchvision\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
  warn(f"Failed to load image Python extension: {e}")


Running on local URL:  http://0.0.0.0:7860
Running on public URL: https://f1f8800d90672a6ac0.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)
</code></pre></div></div>

<div><iframe src="https://f1f8800d90672a6ac0.gradio.live" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="n">gr</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="c1"># Load the tokenizer and model
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">paraphrase_text</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"paraphrase: "</span> <span class="o">+</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
        <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
        <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="n">paraphrased_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">paraphrased_texts</span>

<span class="c1"># Personal Information Section
</span><span class="n">title</span> <span class="o">=</span> <span class="s">"Paraphrasing with T5 Model - Created by Mohsen Dehghani"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s">"""
## Welcome to the Paraphrasing Demo
This demo uses the T5 model fine-tuned on PAWS to generate paraphrases of input text.
Simply enter your text and click 'Submit' to see the results.

**Created by:** Mohsen Dehghani  
**Email:** mohsen.dehghani@gmail.com  
**Location:** Montreal, Quebec, Canada  
"""</span>

<span class="n">article</span> <span class="o">=</span> <span class="s">"""
&lt;p style='text-align: center'&gt;
&lt;a href='https://huggingface.co/Vamsi/T5_Paraphrase_Paws'&gt;Hugging Face Model&lt;/a&gt; | 
&lt;a href='https://github.com/huggingface/transformers'&gt;Transformers Library&lt;/a&gt;
&lt;/p&gt;
"""</span>

<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">"Intelligence Analyst Trainer - 24-968-08-086 All information required to determine suitability for employment with the Canadian Security Intelligence Service is collected under the authority of the Canadian Security Intelligence Service Act."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The Privacy Act allows candidates to review collected information and request amendments."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Machine learning models are improving rapidly, and their applications are expanding across different industries."</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">iface</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">paraphrase_text</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">lines</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s">"Enter text to paraphrase here..."</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Number of paraphrases"</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Beam search size"</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s">"Paraphrased Outputs"</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">,</span>
    <span class="n">examples</span><span class="o">=</span><span class="n">examples</span>
<span class="p">)</span>

<span class="n">iface</span><span class="p">.</span><span class="n">launch</span><span class="p">(</span><span class="n">share</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Running on local URL:  http://127.0.0.1:7860
Running on public URL: https://2c03b010d116b96362.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)
</code></pre></div></div>

<p><a href="https://huggingface.co/spaces/MohsenDehghani/paraphrasing">Visit the Paraphrasing Tool on my Hugging Face</a></p>


	</div>
</article>
		</div>
	</div>
  </body>
</html>