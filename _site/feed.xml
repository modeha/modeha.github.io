<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-02-28T16:06:08-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Deep Learning</title><subtitle>A blog exploring deep learning, AI, and data science topics by Mohsen Dehghani.</subtitle><entry><title type="html">Gradio Paraphrasing Demo</title><link href="http://localhost:4000/2025/01/25/Gradio-Paraphrasing-Demo.html" rel="alternate" type="text/html" title="Gradio Paraphrasing Demo" /><published>2025-01-25T13:10:00-05:00</published><updated>2025-01-25T13:10:00-05:00</updated><id>http://localhost:4000/2025/01/25/Gradio-Paraphrasing-Demo</id><content type="html" xml:base="http://localhost:4000/2025/01/25/Gradio-Paraphrasing-Demo.html"><![CDATA[<h2 id="paraphrasing-text-with-t5-model-using-gradio">Paraphrasing Text with T5 Model Using Gradio</h2>

<p>Paraphrasing is a crucial task in natural language processing (NLP) that involves rephrasing text while retaining its original meaning. 
It has numerous applications, such as content generation, text simplification, and improving readability. In this post,
 we will demonstrate how to build a simple yet effective paraphrasing tool using the T5 (Text-to-Text Transfer Transformer) model, 
 fine-tuned on the PAWS (Paraphrase Adversaries from Word Scrambling) dataset.</p>

<p>We’ll leverage the <strong>Hugging Face Transformers</strong> library to load a pre-trained T5 model and the <strong>Gradio</strong> 
library to create an interactive web-based interface that allows users to input text and generate multiple paraphrased outputs.
 Gradio provides an intuitive and user-friendly way to deploy machine learning models with minimal effort.</p>

<h3 id="key-features-of-the-paraphrasing-tool">Key Features of the Paraphrasing Tool</h3>
<ul>
  <li><strong>Model</strong>: We use the <code class="highlighter-rouge">Vamsi/T5_Paraphrase_Paws</code> model, fine-tuned to generate high-quality paraphrases.</li>
  <li><strong>Input</strong>: Users can enter text into a textbox to be paraphrased.</li>
  <li><strong>Output</strong>: The tool generates multiple paraphrased versions of the input text.</li>
  <li><strong>Customization Options</strong>: Users can adjust the number of paraphrases and beam search size to fine-tune the results.</li>
</ul>

<h3 id="how-it-works">How It Works</h3>
<ol>
  <li>The input text is tokenized and processed using the pre-trained T5 tokenizer.</li>
  <li>The model generates paraphrased outputs by applying beam search, allowing the user to control the number of generated sequences.</li>
  <li>The results are displayed in a user-friendly interface powered by Gradio.</li>
  <li>Example inputs are provided to help users explore the tool’s capabilities.</li>
</ol>

<p>Below is the implementation of the paraphrasing tool as well you can try it yourself:</p>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">torch</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">sentencepiece</span> <span class="n">protobuf</span>

</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="n">gr</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="c1"># Load the tokenizer and model
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"Vamsi/T5_Paraphrase_Paws"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">paraphrase_text</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"paraphrase: "</span> <span class="o">+</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
        <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
        <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="n">paraphrased_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">paraphrased_texts</span>

<span class="c1"># Personal Information Section
</span><span class="n">title</span> <span class="o">=</span> <span class="s">"Paraphrasing with T5 Model - Created by Mohsen Dehghani"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s">"""
## Welcome to the Paraphrasing Demo
This demo uses the T5 model fine-tuned on PAWS to generate paraphrases of input text.
Simply enter your text and click 'Submit' to see the results.

**Created by:** Mohsen Dehghani  
**Email:** mohsen.dehghani@gmail.com  
**Location:** Montreal, Quebec, Canada  
"""</span>

<span class="n">article</span> <span class="o">=</span> <span class="s">"""
&lt;p style='text-align: center'&gt;
&lt;a href='https://huggingface.co/Vamsi/T5_Paraphrase_Paws'&gt;Hugging Face Model&lt;/a&gt; | 
&lt;a href='https://github.com/huggingface/transformers'&gt;Transformers Library&lt;/a&gt;
&lt;/p&gt;
"""</span>

<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">"Intelligence Analyst Trainer - 24-968-08-086 All information required to determine suitability for employment
     with the Canadian Security Intelligence Service is collected under the authority of the Canadian Security Intelligence Service Act."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The Privacy Act allows candidates to review collected information and request amendments."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Machine learning models are improving rapidly, and their applications are expanding across different industries."</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">iface</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">paraphrase_text</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">lines</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s">"Enter text to paraphrase here..."</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Number of paraphrases"</span><span class="p">),</span>
        <span class="n">gr</span><span class="p">.</span><span class="n">Slider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Beam search size"</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">gr</span><span class="p">.</span><span class="n">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s">"Paraphrased Outputs"</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">,</span>
    <span class="n">examples</span><span class="o">=</span><span class="n">examples</span>
<span class="p">)</span>

<span class="n">iface</span><span class="p">.</span><span class="n">launch</span><span class="p">(</span><span class="n">share</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Running on local URL:  http://127.0.0.1:7860
Running on public URL: https://2c03b010d116b96362.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)
</code></pre></div></div>

<p><a href="https://huggingface.co/spaces/MohsenDehghani/paraphrasing" target="_blank">
    <button style="padding: 10px 20px; font-size: 16px;">Visit the Paraphrasing Tool on my Hugging Face</button>
</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paraphrasing Text with T5 Model Using Gradio]]></summary></entry><entry><title type="html">Handwritten Text Recognition</title><link href="http://localhost:4000/2025/01/25/Handwritten-Text-Recognition.html" rel="alternate" type="text/html" title="Handwritten Text Recognition" /><published>2025-01-25T13:06:00-05:00</published><updated>2025-01-25T13:06:00-05:00</updated><id>http://localhost:4000/2025/01/25/Handwritten-Text-Recognition</id><content type="html" xml:base="http://localhost:4000/2025/01/25/Handwritten-Text-Recognition.html"><![CDATA[<h2 id="handwritten-text-recognition"><strong>Handwritten Text Recognition</strong></h2>

<hr />
<p>Handwritten Text Recognition with Tensorflow2 &amp; Keras &amp; IAM Dataset.</p>

<p>Convolutional Recurrent Neural Network. CTC.</p>

<p>Author : Mohsen Dehghani</p>

<h2 id="dataset-used">Dataset used:</h2>

<p>Used in this project: <a href="http://www.fki.inf.unibe.ch/DBs/iamDB/data/words/">IAM Dataset</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPool2D</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Bidirectional</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.activations</span> <span class="kn">import</span> <span class="n">relu</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">softmax</span>
<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">keras_tqdm</span> <span class="kn">import</span> <span class="n">TQDMNotebookCallback</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPool2D</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">LSTM</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./data/words2.txt'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">contents</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">contents</span><span class="p">]</span> 
<span class="n">lines</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">lines</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Define the portion (e.g., 10%)
</span><span class="n">portion</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">portion</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">))</span>

<span class="c1"># Randomly select 10% of the lines
</span><span class="n">lines_subset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">lines_subset</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Original size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span><span class="si">}</span><span class="s">, Subset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lines_subset</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">max_label_len</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">char_list</span> <span class="o">=</span> <span class="s">"!</span><span class="se">\"</span><span class="s">#&amp;'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"</span> 

<span class="c1"># string.ascii_letters + string.digits (Chars &amp; Digits)
# or 
# "!\"#&amp;'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
</span>
<span class="k">print</span><span class="p">(</span><span class="n">char_list</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">encode_to_labels</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="c1"># encoding each output word into digits
</span>    <span class="n">dig_lst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">chara</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
        <span class="n">dig_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char_list</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">chara</span><span class="p">))</span>
        
    <span class="k">return</span> <span class="n">dig_lst</span>

<span class="k">def</span> <span class="nf">decode_to_labels</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
    <span class="s">"""
    Decodes a list of indices back to the corresponding string using char_list.

    Args:
        indices (list of int): List of indices representing encoded characters.

    Returns:
        str: Decoded string.
    """</span>
    <span class="n">decoded_str</span> <span class="o">=</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="n">char_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">decoded_str</span>

<span class="c1"># Example Usage
</span><span class="n">encoded_example</span> <span class="o">=</span> <span class="n">encode_to_labels</span><span class="p">(</span><span class="s">"Hello123"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Encoded:"</span><span class="p">,</span> <span class="n">encoded_example</span><span class="p">)</span>

<span class="n">decoded_example</span> <span class="o">=</span> <span class="n">decode_to_labels</span><span class="p">(</span><span class="n">encoded_example</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Decoded:"</span><span class="p">,</span> <span class="n">decoded_example</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">RECORDS_COUNT</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">train_images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_input_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_label_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_original_text</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">valid_images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_input_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_label_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_original_text</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">inputs_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels_length</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">def</span> <span class="nf">process_image</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="s">"""
    Converts image to shape (32, 128, 1) &amp; normalize
    """</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>

    <span class="c1"># Aspect Ratio Calculation
</span>    <span class="n">new_w</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">new_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="p">(</span><span class="n">new_w</span> <span class="o">/</span> <span class="n">w</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span><span class="p">))</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
    
    <span class="c1"># Converts each to (32, 128, 1)
</span>    <span class="k">if</span> <span class="n">w</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">:</span>
        <span class="n">add_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">((</span><span class="mi">32</span><span class="o">-</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="mi">255</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">img</span><span class="p">,</span> <span class="n">add_zeros</span><span class="p">))</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="k">if</span> <span class="n">h</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">:</span>
        <span class="n">add_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="mi">128</span><span class="o">-</span><span class="n">h</span><span class="p">),</span> <span class="mi">255</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">img</span><span class="p">,</span> <span class="n">add_zeros</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>
        
    <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="mi">128</span> <span class="ow">or</span> <span class="n">w</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">:</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
    
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">subtract</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
    
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Normalize 
</span>    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">/</span> <span class="mi">255</span>
    
    <span class="k">return</span> <span class="n">img</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    
    <span class="k">if</span> <span class="n">status</span> <span class="o">==</span> <span class="s">'ok'</span><span class="p">:</span>
        <span class="n">word_id</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">word</span> <span class="o">=</span> <span class="s">""</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">splits</span><span class="p">[</span><span class="mi">8</span><span class="p">:])</span>
                
        <span class="n">splits_id</span> <span class="o">=</span> <span class="n">word_id</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'-'</span><span class="p">)</span>
        <span class="n">filepath</span> <span class="o">=</span> <span class="s">'words/{}/{}-{}/{}.png'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">splits_id</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                                                  <span class="n">splits_id</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                                                  <span class="n">splits_id</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                                                  <span class="n">word_id</span><span class="p">)</span>
        
        <span class="c1"># process image
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'./data/'</span><span class="o">+</span><span class="n">filepath</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">process_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>
            
        <span class="c1"># process label
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">encode_to_labels</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>
        
        <span class="k">if</span> <span class="n">index</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">valid_images</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">valid_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="n">valid_input_length</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">31</span><span class="p">)</span>
            <span class="n">valid_label_length</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
            <span class="n">valid_original_text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_images</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">train_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="n">train_input_length</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">31</span><span class="p">)</span>
            <span class="n">train_label_length</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
            <span class="n">train_original_text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_label_len</span><span class="p">:</span>
            <span class="n">max_label_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">RECORDS_COUNT</span><span class="p">:</span>
        <span class="k">break</span>
<span class="c1"># Print subset shapes to verify
</span><span class="k">print</span><span class="p">(</span><span class="s">"Subset shapes:"</span><span class="p">,</span> 
      <span class="nb">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">),</span> 
      <span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">),</span> 
      <span class="nb">len</span><span class="p">(</span><span class="n">valid_images</span><span class="p">),</span> 
      <span class="nb">len</span><span class="p">(</span><span class="n">valid_labels</span><span class="p">))</span>
<span class="n">train_padded_label</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> 
                             <span class="n">maxlen</span><span class="o">=</span><span class="n">max_label_len</span><span class="p">,</span> 
                             <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span><span class="p">,</span>
                             <span class="n">value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">))</span>

<span class="n">valid_padded_label</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">valid_labels</span><span class="p">,</span> 
                             <span class="n">maxlen</span><span class="o">=</span><span class="n">max_label_len</span><span class="p">,</span> 
                             <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span><span class="p">,</span>
                             <span class="n">value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">))</span>

<span class="n">train_images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>
<span class="n">train_input_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_input_length</span><span class="p">)</span>
<span class="n">train_label_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_label_length</span><span class="p">)</span>

<span class="n">valid_images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">valid_images</span><span class="p">)</span>
<span class="n">valid_input_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">valid_input_length</span><span class="p">)</span>
<span class="n">valid_label_length</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">valid_label_length</span><span class="p">)</span>
<span class="n">train_images</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">train_padded_label</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">valid_images</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_padded_label</span><span class="p">.</span><span class="n">shape</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original size: 115320, Subset size: 115320
!"#&amp;'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz 78
Encoded: [33, 56, 63, 63, 66, 14, 15, 16]
Decoded: Hello123
Subset shapes: 7579 7579 847 847
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Define input shape (height=32, width=128)
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Convolutional layers
</span><span class="n">conv_1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">pool_1</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">conv_1</span><span class="p">)</span>

<span class="n">conv_2</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">pool_1</span><span class="p">)</span>
<span class="n">pool_2</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">conv_2</span><span class="p">)</span>

<span class="n">conv_3</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">pool_2</span><span class="p">)</span>
<span class="n">conv_4</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">conv_3</span><span class="p">)</span>
<span class="n">pool_4</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">conv_4</span><span class="p">)</span>

<span class="n">conv_5</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">pool_4</span><span class="p">)</span>
<span class="n">batch_norm_5</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">conv_5</span><span class="p">)</span>

<span class="n">conv_6</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">batch_norm_5</span><span class="p">)</span>
<span class="n">batch_norm_6</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">conv_6</span><span class="p">)</span>
<span class="n">pool_6</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">batch_norm_6</span><span class="p">)</span>

<span class="n">conv_7</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">pool_6</span><span class="p">)</span>

<span class="n">squeezed</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">K</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">conv_7</span><span class="p">)</span>

<span class="c1"># Bidirectional LSTM layers
</span><span class="n">blstm_1</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))(</span><span class="n">squeezed</span><span class="p">)</span>
<span class="n">blstm_2</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))(</span><span class="n">blstm_1</span><span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">char_list</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)(</span><span class="n">blstm_2</span><span class="p">)</span>

<span class="c1"># Model for prediction
</span><span class="n">act_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

<span class="c1"># Inputs for training (additional)
</span><span class="n">the_labels</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'the_labels'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">max_label_len</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">)</span>
<span class="n">input_length</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'input_length'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">label_length</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'label_length'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int64'</span><span class="p">)</span>

<span class="c1"># Define the custom CTC loss function
</span><span class="k">def</span> <span class="nf">ctc_lambda_func</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span> <span class="o">=</span> <span class="n">args</span>
    <span class="k">return</span> <span class="n">K</span><span class="p">.</span><span class="n">ctc_batch_cost</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">)</span>

<span class="c1"># Add the CTC loss layer
</span><span class="n">loss_out</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">ctc_lambda_func</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s">'ctc'</span><span class="p">)([</span><span class="n">outputs</span><span class="p">,</span> <span class="n">the_labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">])</span>

<span class="c1"># Training model with CTC loss
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">inputs</span><span class="p">,</span> <span class="n">the_labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">loss_out</span><span class="p">)</span>

<span class="c1"># Compile the model
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="s">'adam'</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s">'ctc'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">},</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_name</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># Callbacks setup
</span><span class="n">model_save_path</span> <span class="o">=</span> <span class="s">"./ocr_ctc_model"</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">filepath</span><span class="o">=</span><span class="n">model_save_path</span> <span class="o">+</span> <span class="s">'/best_model.h5'</span><span class="p">,</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span>
<span class="p">)</span>

<span class="n">plot_callback</span> <span class="o">=</span> <span class="n">TrainingPlot</span><span class="p">()</span>
<span class="n">callbacks_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">plot_callback</span><span class="p">]</span>

<span class="c1"># Save the model without the CTC loss for better reusability
</span><span class="n">model_without_ctc</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<span class="n">model_without_ctc</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_save_path</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="s">'tf'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model saved successfully to </span><span class="si">{</span><span class="n">model_save_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Training with callbacks
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_padded_label</span><span class="p">,</span> <span class="n">train_input_length</span><span class="p">,</span> <span class="n">train_label_length</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">)),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span>
        <span class="p">[</span><span class="n">valid_images</span><span class="p">,</span> <span class="n">valid_padded_label</span><span class="p">,</span> <span class="n">valid_input_length</span><span class="p">,</span> <span class="n">valid_label_length</span><span class="p">],</span>
        <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_images</span><span class="p">))]</span>
    <span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_list</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Training complete. Model saved successfully."</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="/assets/figures/IAM_accuracy.png" /></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>948/948 [==============================] - 555s 585ms/step - loss: 3.0008 - accuracy: 0.3644 - val_loss: 5.7751 - val_accuracy: 0.3542
Training complete. Model saved successfully.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>


<span class="c1"># Load the saved model without CTC for inference or re-training
</span><span class="n">loaded_model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_save_path</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Model loaded successfully."</span><span class="p">)</span>

<span class="c1"># Re-add the CTC loss Lambda layer
</span><span class="n">loss_out</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">ctc_lambda_func</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s">'ctc'</span><span class="p">)(</span>
    <span class="p">[</span><span class="n">loaded_model</span><span class="p">.</span><span class="n">output</span><span class="p">,</span> <span class="n">the_labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Build the complete model again with CTC loss
</span><span class="n">final_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">loaded_model</span><span class="p">.</span><span class="nb">input</span><span class="p">,</span> <span class="n">the_labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">loss_out</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"CTC layer re-added successfully."</span><span class="p">)</span>

<span class="c1"># Compile the model again with the same optimizer
</span><span class="n">final_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s">'ctc'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">},</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_name</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># Define Callbacks for Resuming Training
</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">filepath</span><span class="o">=</span><span class="s">"./ocr_ctc_model/best_model_resume.h5"</span><span class="p">,</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span>
<span class="p">)</span>


<span class="c1"># Callbacks list
</span><span class="n">callbacks_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">plot_callback</span><span class="p">]</span>

<span class="c1"># Continue training from the last saved epoch (starting from epoch 3)
</span><span class="n">initial_epoch</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Training previously done for 2 epochs
</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">final_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_padded_label</span><span class="p">,</span> <span class="n">train_input_length</span><span class="p">,</span> <span class="n">train_label_length</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">)),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># Continue training till epoch 5
</span>    <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>  <span class="c1"># Start from epoch 3
</span>    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span>
        <span class="p">[</span><span class="n">valid_images</span><span class="p">,</span> <span class="n">valid_padded_label</span><span class="p">,</span> <span class="n">valid_input_length</span><span class="p">,</span> <span class="n">valid_label_length</span><span class="p">],</span>
        <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_images</span><span class="p">))]</span>
    <span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_list</span>  <span class="c1"># Including checkpointing and plotting
</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Training resumed and completed successfully."</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="training-accuracy">Training Accuracy</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predict outputs on validation images
</span><span class="n">m</span><span class="o">=</span><span class="mi">1</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">act_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">m</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
 
<span class="c1"># use CTC decoder
</span><span class="n">decoded</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">ctc_decode</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span>   
                       <span class="n">input_length</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">prediction</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">prediction</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                       <span class="n">greedy</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">decoded</span><span class="p">)</span>

<span class="c1"># see the results
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"original_text =  "</span><span class="p">,</span> <span class="n">train_original_text</span><span class="p">[</span><span class="n">m</span><span class="o">+</span><span class="n">i</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"predicted text = "</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s">''</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">char_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)],</span> <span class="n">end</span> <span class="o">=</span> <span class="s">''</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">m</span><span class="o">+</span><span class="n">i</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">128</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">gray</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1/1 [==============================] - 0s 169ms/step
original_text =   taken
predicted text = taken
</code></pre></div></div>

<p><img src="/assets/figures/IAM_accuracy2.png" /></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Handwritten Text Recognition]]></summary></entry><entry><title type="html">Image Kernels Explained Visually</title><link href="http://localhost:4000/2024/12/13/Image-Kernels-Explained-Visually.html" rel="alternate" type="text/html" title="Image Kernels Explained Visually" /><published>2024-12-13T21:26:00-05:00</published><updated>2024-12-13T21:26:00-05:00</updated><id>http://localhost:4000/2024/12/13/Image-Kernels-Explained-Visually</id><content type="html" xml:base="http://localhost:4000/2024/12/13/Image-Kernels-Explained-Visually.html"><![CDATA[<iframe src="https://setosa.io/ev/image-kernels/" width="100%" height="800px" style="border:none;">
</iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">US Airline Tweet Sentiment Analysis</title><link href="http://localhost:4000/2024/12/13/US-Airline-Tweet-Sentiment-Analysis.html" rel="alternate" type="text/html" title="US Airline Tweet Sentiment Analysis" /><published>2024-12-13T21:26:00-05:00</published><updated>2024-12-13T21:26:00-05:00</updated><id>http://localhost:4000/2024/12/13/US%20Airline-Tweet-Sentiment-Analysis</id><content type="html" xml:base="http://localhost:4000/2024/12/13/US-Airline-Tweet-Sentiment-Analysis.html"><![CDATA[<iframe src="https://www.comet.com/alilina1978/nlp-twitter-airline/notes" width="100%" height="800px" style="border:none;">
</iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">The Four Fundamental Concepts of Object-Oriented Programming (OOP)</title><link href="http://localhost:4000/2024/12/02/the-four-fundamental-concepts-of-object-oriented-programming-oop.html" rel="alternate" type="text/html" title="The Four Fundamental Concepts of Object-Oriented Programming (OOP)" /><published>2024-12-02T00:59:00-05:00</published><updated>2024-12-02T00:59:00-05:00</updated><id>http://localhost:4000/2024/12/02/the-four-fundamental-concepts-of-object-oriented-programming-oop</id><content type="html" xml:base="http://localhost:4000/2024/12/02/the-four-fundamental-concepts-of-object-oriented-programming-oop.html"><![CDATA[<h3 id="1-encapsulation"><strong>1. Encapsulation</strong></h3>
<ul>
  <li><strong>Definition</strong>: Encapsulation is the bundling of data (attributes) and methods (functions) into a single unit (class) and restricting direct access to some of the object’s components.
   <strong>Encapsulation also involves restricting direct access to certain parts of an object to ensure better control and data integrity</strong>.</li>
  <li><strong>Purpose</strong>: Protect the data from unauthorized access and ensure proper control.</li>
  <li><strong>Example</strong>: Using private attributes and getter/setter methods (as explained above).</li>
</ul>

<hr />

<h3 id="2-abstraction"><strong>2. Abstraction</strong></h3>
<ul>
  <li><strong>Definition</strong>: Abstraction is the concept of hiding unnecessary implementation details and showing only the essential features of an object.</li>
  <li><strong>Purpose</strong>: Simplifies complexity by focusing on what an object does rather than how it does it.</li>
  <li><strong>Example in Python</strong>:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="k">class</span> <span class="nc">Animal</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>  <span class="c1"># Abstract class
</span>    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">make_sound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">make_sound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"Bark!"</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">make_sound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"Meow!"</span>

<span class="n">dog</span> <span class="o">=</span> <span class="n">Dog</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">dog</span><span class="p">.</span><span class="n">make_sound</span><span class="p">())</span>  <span class="c1"># Output: Bark!
</span></code></pre></div>    </div>
    <ul>
      <li><code class="highlighter-rouge">Animal</code> defines an abstract class with an abstract method <code class="highlighter-rouge">make_sound</code>. The subclasses (<code class="highlighter-rouge">Dog</code> and <code class="highlighter-rouge">Cat</code>) provide specific implementations.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="3-inheritance"><strong>3. Inheritance</strong></h3>
<ul>
  <li><strong>Definition</strong>: Inheritance allows one class (child/subclass) to acquire the properties and behaviors of another class (parent/superclass).</li>
  <li><strong>Purpose</strong>: Promotes code reuse and establishes a hierarchical relationship between classes.</li>
  <li><strong>Example in Python</strong>:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Vehicle</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">brand</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">brand</span> <span class="o">=</span> <span class="n">brand</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">display_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s">"Vehicle: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">brand</span><span class="si">}</span><span class="s"> </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="si">}</span><span class="s">"</span>

<span class="k">class</span> <span class="nc">Car</span><span class="p">(</span><span class="n">Vehicle</span><span class="p">):</span>  <span class="c1"># Inheriting from Vehicle
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">brand</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">doors</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">brand</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">doors</span> <span class="o">=</span> <span class="n">doors</span>

    <span class="k">def</span> <span class="nf">display_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s">"Car: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">brand</span><span class="si">}</span><span class="s"> </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="si">}</span><span class="s">, Doors: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">doors</span><span class="si">}</span><span class="s">"</span>

<span class="n">car</span> <span class="o">=</span> <span class="n">Car</span><span class="p">(</span><span class="s">"Toyota"</span><span class="p">,</span> <span class="s">"Corolla"</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">car</span><span class="p">.</span><span class="n">display_info</span><span class="p">())</span>  <span class="c1"># Output: Car: Toyota Corolla, Doors: 4
</span></code></pre></div>    </div>
    <ul>
      <li><code class="highlighter-rouge">Car</code> inherits from <code class="highlighter-rouge">Vehicle</code> and adds its own specific behavior (<code class="highlighter-rouge">doors</code> attribute).</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="4-polymorphism"><strong>4. Polymorphism</strong></h3>
<ul>
  <li><strong>Definition</strong>: Polymorphism allows objects of different classes to be treated as objects of a common superclass. It enables the same method to behave differently based on the object calling it.</li>
  <li><strong>Purpose</strong>: Promotes flexibility and scalability in code.</li>
  <li><strong>Example in Python</strong>:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Shape</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">area</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Rectangle</span><span class="p">(</span><span class="n">Shape</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">height</span> <span class="o">=</span> <span class="n">height</span>

    <span class="k">def</span> <span class="nf">area</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">height</span>

<span class="k">class</span> <span class="nc">Circle</span><span class="p">(</span><span class="n">Shape</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">radius</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">radius</span> <span class="o">=</span> <span class="n">radius</span>

    <span class="k">def</span> <span class="nf">area</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">3.14</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">radius</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">radius</span>

<span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Rectangle</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">Circle</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">shape</span><span class="p">.</span><span class="n">area</span><span class="p">())</span>
</code></pre></div>    </div>
    <ul>
      <li>Output:
        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20
28.26
</code></pre></div>        </div>
      </li>
      <li>Both <code class="highlighter-rouge">Rectangle</code> and <code class="highlighter-rouge">Circle</code> have the <code class="highlighter-rouge">area</code> method, but they implement it differently.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="summary-of-oop-principles">Summary of OOP Principles:</h3>
<p>| <strong>Concept</strong>      | <strong>Definition</strong>                                                      | <strong>Purpose</strong>                                |
|——————-|——————————————————————–|——————————————–|
| <strong>Encapsulation</strong> | Protects data and ensures controlled access using access modifiers. | Data protection and integrity              |
| <strong>Abstraction</strong>   | Hides implementation details and focuses on functionality.          | Reduces complexity and increases usability |
| <strong>Inheritance</strong>   | Enables one class to inherit properties and methods from another.   | Code reuse and hierarchical relationships  |
| <strong>Polymorphism</strong>  | Allows the same method to behave differently for different objects.  | Flexibility and dynamic method execution   |</p>]]></content><author><name></name></author><summary type="html"><![CDATA[1. Encapsulation Definition: Encapsulation is the bundling of data (attributes) and methods (functions) into a single unit (class) and restricting direct access to some of the object’s components. Encapsulation also involves restricting direct access to certain parts of an object to ensure better control and data integrity. Purpose: Protect the data from unauthorized access and ensure proper control. Example: Using private attributes and getter/setter methods (as explained above).]]></summary></entry><entry><title type="html">Mastering Git: A Comprehensive Guide to Branching, Tracking, and Collaboration</title><link href="http://localhost:4000/2024/12/01/mastering-git-a-comprehensive-guide-to-branching-tracking-and-collaboration.html" rel="alternate" type="text/html" title="Mastering Git: A Comprehensive Guide to Branching, Tracking, and Collaboration" /><published>2024-12-01T21:26:00-05:00</published><updated>2024-12-01T21:26:00-05:00</updated><id>http://localhost:4000/2024/12/01/mastering-git-a-comprehensive-guide-to-branching-tracking-and-collaboration</id><content type="html" xml:base="http://localhost:4000/2024/12/01/mastering-git-a-comprehensive-guide-to-branching-tracking-and-collaboration.html"><![CDATA[<h4 id="introduction"><strong>Introduction</strong></h4>
<p>Git is an essential tool for modern software development, enabling seamless collaboration and efficient version control. In this guide, we’ll explore creating branches, pushing changes, setting upstream tracking, and working with remote repositories to enhance your Git workflow.</p>

<hr />

<h4 id="creating-a-new-branch"><strong>Creating a New Branch</strong></h4>
<p>Creating branches is a fundamental part of Git, allowing developers to isolate features, bug fixes, or experiments. Here’s how you can create and work with branches:</p>

<ol>
  <li><strong>Create a New Branch Locally:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch branch-name
</code></pre></div>    </div>
    <ul>
      <li>Creates a branch but keeps you on the current one.</li>
    </ul>
  </li>
  <li><strong>Create and Switch in One Command:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout <span class="nt">-b</span> branch-name
</code></pre></div>    </div>
    <ul>
      <li>This is the most commonly used method.</li>
    </ul>
  </li>
  <li><strong>Check Your Branches:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch
</code></pre></div>    </div>
    <ul>
      <li>Displays all local branches, with <code class="highlighter-rouge">*</code> indicating the active one.</li>
    </ul>
  </li>
  <li><strong>Push the New Branch to the Remote:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push <span class="nt">-u</span> origin branch-name
</code></pre></div>    </div>
    <ul>
      <li>Links the local branch with the remote repository for easier future pushes.</li>
    </ul>
  </li>
</ol>

<hr />

<h4 id="understanding-git-push--u"><strong>Understanding <code class="highlighter-rouge">git push -u</code></strong></h4>
<p>The <code class="highlighter-rouge">-u</code> option (short for “set upstream”) links your local branch to a remote branch. This simplifies subsequent Git commands, as you can omit the remote and branch name:</p>

<ul>
  <li>First push with upstream tracking:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push <span class="nt">-u</span> origin branch-name
</code></pre></div>    </div>
  </li>
  <li>Future pushes and pulls:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push
git pull
</code></pre></div>    </div>
  </li>
</ul>

<p>This is particularly useful when creating new branches or pulling remote branches for the first time.</p>

<hr />

<h4 id="pushing-files-to-a-repository"><strong>Pushing Files to a Repository</strong></h4>
<p>Once you’ve added or modified files, pushing them to a repository involves these steps:</p>

<ol>
  <li><strong>Add Files to the Staging Area:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add file1 file2
</code></pre></div>    </div>
  </li>
  <li><strong>Commit the Changes:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git commit <span class="nt">-m</span> <span class="s2">"Describe your changes"</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Push the Changes to the Remote Repository:</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push
</code></pre></div>    </div>
  </li>
</ol>

<p>For new branches, use <code class="highlighter-rouge">git push -u origin branch-name</code> to set up the upstream tracking.</p>

<hr />

<h4 id="working-with-an-existing-branch"><strong>Working with an Existing Branch</strong></h4>
<p>If you’re adding files to an existing branch in a repository, the workflow becomes even simpler:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout branch-name
git add file1 file2
git commit <span class="nt">-m</span> <span class="s2">"Describe your changes"</span>
git push
</code></pre></div></div>

<hr />

<h4 id="switching-between-branches"><strong>Switching Between Branches</strong></h4>
<p>Easily switch between branches:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout branch-name
</code></pre></div></div>
<p>Ensure you commit or stash changes before switching to avoid conflicts.</p>

<hr />

<h4 id="best-practices-for-branching-and-collaboration"><strong>Best Practices for Branching and Collaboration</strong></h4>
<ul>
  <li><strong>Create Separate Branches</strong> for each feature or bug fix.</li>
  <li><strong>Commit Frequently</strong> with meaningful messages.</li>
  <li>Use <strong>Pull Requests (PRs)</strong> for code reviews and merging changes into the main branch.</li>
  <li>Regularly <strong>sync with the remote repository</strong> using <code class="highlighter-rouge">git pull</code> to avoid conflicts.</li>
</ul>

<hr />

<h4 id="conclusion"><strong>Conclusion</strong></h4>
<p>By mastering Git commands like <code class="highlighter-rouge">git branch</code>, <code class="highlighter-rouge">git checkout</code>, and <code class="highlighter-rouge">git push -u</code>, you can streamline your development workflow and collaborate effectively with your team. With this guide, you’re well-equipped to navigate Git’s powerful branching and tracking capabilities.</p>

<h4 id="to-see-the-differences-between-branches-in-git"><strong>To see the differences between branches in Git</strong></h4>

<p>To see the differences between branches in Git, you can use the <code class="highlighter-rouge">git diff</code> command. Below are several methods to view differences between branches.</p>

<hr />

<h3 id="1-view-differences-between-two-branches"><strong>1. View Differences Between Two Branches</strong></h3>
<p>You can compare two branches using:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch1 branch2
</code></pre></div></div>
<ul>
  <li>This shows what changes exist in <code class="highlighter-rouge">branch2</code> that are not in <code class="highlighter-rouge">branch1</code>.</li>
</ul>

<h4 id="example">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff main feature-branch
</code></pre></div></div>
<ul>
  <li>This shows what changes are in <code class="highlighter-rouge">feature-branch</code> compared to <code class="highlighter-rouge">main</code>.</li>
</ul>

<hr />

<h3 id="2-compare-current-branch-with-another-branch"><strong>2. Compare Current Branch with Another Branch</strong></h3>
<p>If you want to compare your current branch with another branch:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch-name
</code></pre></div></div>

<h4 id="example-1">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff feature-branch
</code></pre></div></div>
<ul>
  <li>Compares your current branch to <code class="highlighter-rouge">feature-branch</code>.</li>
</ul>

<hr />

<h3 id="3-compare-a-branch-with-the-remote-version"><strong>3. Compare a Branch with the Remote Version</strong></h3>
<p>If you want to see differences between a local branch and its remote counterpart:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch-name origin/branch-name
</code></pre></div></div>

<h4 id="example-2">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff feature-branch origin/feature-branch
</code></pre></div></div>
<ul>
  <li>Shows differences between your local and remote <code class="highlighter-rouge">feature-branch</code>.</li>
</ul>

<hr />

<h3 id="4-compare-only-specific-files-or-directories"><strong>4. Compare Only Specific Files or Directories</strong></h3>
<p>To narrow the comparison to specific files or directories, add the path:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch1 branch2 <span class="nt">--</span> path/to/file
</code></pre></div></div>

<h4 id="example-3">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff main feature-branch <span class="nt">--</span> src/app.js
</code></pre></div></div>
<ul>
  <li>Compares <code class="highlighter-rouge">src/app.js</code> between <code class="highlighter-rouge">main</code> and <code class="highlighter-rouge">feature-branch</code>.</li>
</ul>

<hr />

<h3 id="5-view-a-summary-of-changes"><strong>5. View a Summary of Changes</strong></h3>
<p>If you don’t need the detailed diff but just want to see a summary:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff <span class="nt">--stat</span> branch1 branch2
</code></pre></div></div>

<h4 id="example-4">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff <span class="nt">--stat</span> main feature-branch
</code></pre></div></div>
<ul>
  <li>Outputs a summary of added, modified, and deleted files.</li>
</ul>

<hr />

<h3 id="6-compare-merged-and-unmerged-changes"><strong>6. Compare Merged and Unmerged Changes</strong></h3>
<p>To see changes in a branch that haven’t been merged into another branch:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch1...branch2
</code></pre></div></div>
<h4 id="example-5">Example:</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff main...feature-branch
</code></pre></div></div>
<ul>
  <li>Shows changes in <code class="highlighter-rouge">feature-branch</code> that are not in <code class="highlighter-rouge">main</code>.</li>
</ul>

<hr />

<h3 id="7-using-a-gui-for-better-visualization"><strong>7. Using a GUI for Better Visualization</strong></h3>
<p>You can use Git GUI tools for an easier way to view differences:</p>
<ul>
  <li><strong>GitHub Desktop</strong></li>
  <li><strong>GitKraken</strong></li>
  <li><strong>SourceTree</strong></li>
  <li><strong>VSCode Git Extension</strong></li>
</ul>

<h4 id="example-using-git-log-with-diff">Example Using <code class="highlighter-rouge">git log</code> with Diff:</h4>
<p>For a graphical log with differences, use:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="nt">--oneline</span> <span class="nt">--graph</span> <span class="nt">--decorate</span> <span class="nt">--branches</span>
</code></pre></div></div>

<hr />

<h3 id="8-visualize-differences-with-git-difftool"><strong>8. Visualize Differences with <code class="highlighter-rouge">git difftool</code></strong></h3>
<p>If you have a diff tool like <code class="highlighter-rouge">vimdiff</code>, <code class="highlighter-rouge">meld</code>, or <code class="highlighter-rouge">kdiff3</code> installed:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git difftool branch1 branch2
</code></pre></div></div>

<hr />

<h3 id="9-compare-working-directory-with-a-branch"><strong>9. Compare Working Directory with a Branch</strong></h3>
<p>To see what changes are in your working directory compared to a branch:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff branch-name
</code></pre></div></div>

<hr />

<h3 id="summary-table-of-commands">Summary Table of Commands</h3>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="highlighter-rouge">git diff branch1 branch2</code></td>
      <td>Compare two branches.</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">git diff branch-name</code></td>
      <td>Compare current branch with another branch.</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">git diff --stat branch1 branch2</code></td>
      <td>Show a summary of changes.</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">git diff branch1...branch2</code></td>
      <td>Show changes in a branch not yet merged.</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">git difftool branch1 branch2</code></td>
      <td>Use a visual tool to compare branches.</td>
    </tr>
  </tbody>
</table>

<hr />

<h3 id="practical-example">Practical Example:</h3>
<p>You are on <code class="highlighter-rouge">main</code> and want to see what’s different in <code class="highlighter-rouge">feature-branch</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff main feature-branch
</code></pre></div></div>

<p>This shows the line-by-line differences between <code class="highlighter-rouge">main</code> and <code class="highlighter-rouge">feature-branch</code>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction Git is an essential tool for modern software development, enabling seamless collaboration and efficient version control. In this guide, we’ll explore creating branches, pushing changes, setting upstream tracking, and working with remote repositories to enhance your Git workflow.]]></summary></entry><entry><title type="html">Understanding Large Language Models (LLMs): A Comprehensive Guide</title><link href="http://localhost:4000/2024/11/26/understanding-large-language-models-llms-a-comprehensive-guide.html" rel="alternate" type="text/html" title="Understanding Large Language Models (LLMs): A Comprehensive Guide" /><published>2024-11-26T23:04:00-05:00</published><updated>2024-11-26T23:04:00-05:00</updated><id>http://localhost:4000/2024/11/26/understanding-large-language-models-llms-a-comprehensive-guide</id><content type="html" xml:base="http://localhost:4000/2024/11/26/understanding-large-language-models-llms-a-comprehensive-guide.html"><![CDATA[<p><strong>How LLM Technology Actually Works</strong></p>

<p>This text explores the inner workings of large language models (LLMs) and their applications in various fields. The topics covered include:</p>

<ol>
  <li><strong>Model Training</strong></li>
  <li><strong>Instruction Tuning</strong></li>
  <li><strong>Fine-tuning</strong></li>
  <li><strong>The Generative AI Project Lifecycle Framework</strong></li>
</ol>

<hr />

<h3 id="generative-ai-and-llms-as-general-purpose-technology"><strong>Generative AI and LLMs as General-Purpose Technology</strong></h3>

<p>Generative AI, and LLMs specifically, represent a general-purpose technology. Similar to other transformative technologies like deep learning or electricity, LLMs are not limited to a single application but span a wide range of use cases across various industries.</p>

<p>Similar to the rise of deep learning about 15 years ago, there is much work ahead to fully utilize LLMs. Since the technology is still relatively new and only a small number of people understand how to build applications with it, many companies are currently scrambling to find and hire experts in the field.</p>

<hr />

<h3 id="generative-ai-project-lifecycle"><strong>Generative AI Project Lifecycle</strong></h3>

<p>This text details the typical lifecycle of a generative AI project, including:</p>

<ul>
  <li>Scoping the problem.</li>
  <li>Selecting a language model.</li>
  <li>Optimizing a model for deployment.</li>
  <li>Integrating it into applications.</li>
</ul>

<p>The transformer architecture powers large language models. This text also explains how these models are trained and the compute resources required to develop these powerful systems.</p>

<hr />

<h3 id="inference-prompt-engineering-and-parameter-tuning"><strong>Inference, Prompt Engineering, and Parameter Tuning</strong></h3>

<p>How do you guide a model during inference? This involves techniques like prompt engineering and adjusting key generation parameters for better outputs. Some aspects include:</p>

<ul>
  <li><strong>Instruction Fine-tuning</strong>: Adapting pre-trained models to specific tasks and datasets.</li>
  <li><strong>Alignment</strong>: Ensuring outputs align with human values, decreasing harmful or toxic responses.</li>
  <li><strong>Exploration of Sampling Strategies</strong>: Tuning inference parameters to improve generative outputs.</li>
</ul>

<hr />

<h3 id="efficiency-with-peft-and-rlhf"><strong>Efficiency with PEFT and RLHF</strong></h3>

<ul>
  <li><strong>Parameter-Efficient Fine-Tuning (PEFT)</strong>: A methodology for streamlining workflows.</li>
  <li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong>: Training reward models to classify responses as toxic or non-toxic for better alignment.</li>
</ul>

<hr />

<h3 id="the-transformer-architecture"><strong>The Transformer Architecture</strong></h3>

<p>The transformer architecture, introduced in the 2017 paper “Attention Is All You Need,” laid the foundation for modern LLMs. This architecture relies on self-attention and multi-headed self-attention mechanisms, enabling models to effectively process and understand language. Key attributes include:</p>

<ol>
  <li><strong>Parallelization</strong>: Transformers can process inputs in parallel, making them efficient on modern GPUs.</li>
  <li><strong>Scalability</strong>: The architecture is highly scalable and remains the state-of-the-art for many NLP tasks.</li>
</ol>

<hr />

<h3 id="understanding-transformer-networks"><strong>Understanding Transformer Networks</strong></h3>

<p>When the transformer paper first emerged, its mathematical complexity made it seem “magical.” Over time, researchers have developed better intuitions about terms like multi-headed attention and the role of parallelism, which has allowed transformers to scale effectively.</p>

<p>Transformers process input tokens in parallel and can compute relationships between words using learned attention weights, enabling them to encode language contextually.</p>

<hr />

<h3 id="beyond-transformers-generative-ai-project-lifecycle"><strong>Beyond Transformers: Generative AI Project Lifecycle</strong></h3>

<p>In addition to understanding transformers, it is essential to explore the <strong>Generative AI Project Lifecycle</strong>, which covers:</p>

<ol>
  <li>Deciding whether to use a pre-trained model or train from scratch.</li>
  <li>Fine-tuning and customizing models for specific data.</li>
  <li>Evaluating different model sizes and architectures based on use cases, from massive 100-billion-parameter models to smaller, task-specific ones.</li>
</ol>

<hr />

<h3 id="applications-of-llms"><strong>Applications of LLMs</strong></h3>

<p>Large language models are powerful tools that extend beyond chat-based applications. Some use cases include:</p>

<ul>
  <li><strong>Text Summarization</strong>: Summarizing dialogue or long-form text.</li>
  <li><strong>Language Translation</strong>: Translating text between human languages or natural language into code.</li>
  <li><strong>Information Retrieval</strong>: Extracting named entities, relationships, or structured information from unstructured data.</li>
  <li><strong>Creative Writing</strong>: Generating essays, poems, or stories.</li>
  <li><strong>Code Generation</strong>: Writing code snippets for programming tasks.</li>
</ul>

<hr />

<h3 id="model-training-and-scalability"><strong>Model Training and Scalability</strong></h3>

<p>Modern LLMs are trained on massive datasets containing trillions of words, using enormous compute power. These “foundation models” exhibit emergent properties, enabling them to solve tasks they were not explicitly trained for.</p>

<ul>
  <li><strong>Large Models for General Knowledge</strong>: Models with hundreds of billions of parameters are better suited for tasks requiring broad knowledge.</li>
  <li><strong>Smaller Models for Specific Use Cases</strong>: Small, fine-tuned models can achieve excellent results on narrow tasks, often with significantly lower resource requirements.</li>
</ul>

<hr />

<h3 id="core-concepts-of-transformer-architectures"><strong>Core Concepts of Transformer Architectures</strong></h3>

<p>Transformers consist of two main components:</p>
<ol>
  <li><strong>Encoder</strong>: Encodes input sequences into meaningful representations.</li>
  <li><strong>Decoder</strong>: Generates outputs based on the encoded input.</li>
</ol>

<p>These components rely on processes like tokenization, embedding layers, and positional encodings to process text. Multi-headed self-attention layers compute relationships between tokens, learning the context and structure of language. Output probabilities are then normalized using the softmax function to generate predictions.</p>

<hr />

<h3 id="variants-of-transformer-models"><strong>Variants of Transformer Models</strong></h3>
<ol>
  <li><strong>Encoder-only Models</strong>: Ideal for classification tasks (e.g., BERT).</li>
  <li><strong>Encoder-Decoder Models</strong>: Suitable for sequence-to-sequence tasks like translation (e.g., BART, T5).</li>
  <li><strong>Decoder-only Models</strong>: General-purpose text generation models (e.g., GPT, BLOOM).</li>
</ol>

<hr />

<h3 id="prompt-engineering-and-inference-techniques"><strong>Prompt Engineering and Inference Techniques</strong></h3>

<p>The interaction between humans and LLMs involves crafting <strong>prompts</strong>, which are fed into the model’s <strong>context window</strong> for inference. Prompt engineering strategies include:</p>

<ul>
  <li><strong>Zero-shot Inference</strong>: Providing no examples.</li>
  <li><strong>One-shot Inference</strong>: Providing one example in the prompt.</li>
  <li><strong>Few-shot Inference</strong>: Providing multiple examples to guide the model’s behavior.</li>
</ul>

<hr />

<h3 id="controlling-model-output"><strong>Controlling Model Output</strong></h3>

<p>Key parameters for tuning model behavior include:</p>
<ul>
  <li><strong>Max New Tokens</strong>: Limits the number of generated tokens.</li>
  <li><strong>Top-k Sampling</strong>: Chooses from the top-k most probable tokens.</li>
  <li><strong>Top-p Sampling (Nucleus)</strong>: Selects tokens based on cumulative probabilities.</li>
  <li><strong>Temperature</strong>: Adjusts randomness in token selection.</li>
</ul>

<hr />

<h3 id="conclusion"><strong>Conclusion</strong></h3>

<p>The advancements in transformer architectures and the ability to fine-tune models have made LLMs incredibly versatile. From natural language generation to domain-specific applications, understanding concepts like prompt engineering, attention mechanisms, and generative AI project lifecycles equips developers with the tools to unlock the full potential of these technologies. This course will guide you through these critical stages to help you build and deploy your LLM-powered applications.</p>

<hr />]]></content><author><name></name></author><summary type="html"><![CDATA[How LLM Technology Actually Works]]></summary></entry><entry><title type="html">Understanding Greedy Decoding in Machine Learning: A Simple Approach to Text Generation</title><link href="http://localhost:4000/2024/11/26/understanding-greedy-decoding-in-machine-learning-a-simple-approach-to-text-generation.html" rel="alternate" type="text/html" title="Understanding Greedy Decoding in Machine Learning: A Simple Approach to Text Generation" /><published>2024-11-26T22:44:00-05:00</published><updated>2024-11-26T22:44:00-05:00</updated><id>http://localhost:4000/2024/11/26/understanding-greedy-decoding-in-machine-learning-a-simple-approach-to-text-generation</id><content type="html" xml:base="http://localhost:4000/2024/11/26/understanding-greedy-decoding-in-machine-learning-a-simple-approach-to-text-generation.html"><![CDATA[<p><strong>Greedy Decoding</strong> is a <strong>text generation technique</strong> used in Natural Language Processing (NLP), particularly with models like GPT, T5, or other transformer-based models, to generate output token by token. It is one of the simplest decoding strategies and focuses on selecting the most likely next token at each step.</p>

<hr />

<h3 id="how-greedy-decoding-works"><strong>How Greedy Decoding Works</strong></h3>
<ol>
  <li><strong>Step-by-Step Token Generation</strong>:
    <ul>
      <li>At each generation step, the model predicts a <strong>probability distribution</strong> over all possible tokens in the vocabulary.</li>
      <li>Greedy decoding selects the token with the <strong>highest probability</strong> (argmax) from the distribution.</li>
    </ul>
  </li>
  <li><strong>Sequential Process</strong>:
    <ul>
      <li>The chosen token is appended to the generated sequence.</li>
      <li>The model then uses this updated sequence as input to predict the next token.</li>
      <li>This process continues until:
        <ul>
          <li>A special <strong>end-of-sequence (EOS)</strong> token is generated.</li>
          <li>A predefined <strong>maximum length</strong> is reached.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h3 id="advantages-of-greedy-decoding"><strong>Advantages of Greedy Decoding</strong></h3>
<ol>
  <li><strong>Simplicity</strong>:
    <ul>
      <li>It is computationally efficient and straightforward to implement.</li>
    </ul>
  </li>
  <li><strong>Deterministic</strong>:
    <ul>
      <li>Given the same input, greedy decoding will always produce the same output, making it predictable.</li>
    </ul>
  </li>
</ol>

<hr />

<h3 id="disadvantages-of-greedy-decoding"><strong>Disadvantages of Greedy Decoding</strong></h3>
<ol>
  <li><strong>Suboptimal Results</strong>:
    <ul>
      <li>Greedy decoding can <strong>miss the globally optimal sequence</strong> because it focuses only on the most probable token at each step, without considering future tokens.</li>
      <li>Example:
        <ul>
          <li>Model prediction for a sentence: “The cat is on the [mat, roof, bed].”</li>
          <li>Greedy decoding might pick “mat” (highest probability), but “roof” could lead to a more coherent sequence later.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Lack of Diversity</strong>:
    <ul>
      <li>It generates repetitive or overly generic outputs, especially in tasks like storytelling or dialogue generation.</li>
    </ul>
  </li>
  <li><strong>Poor Performance in Ambiguous Contexts</strong>:
    <ul>
      <li>If multiple plausible tokens have similar probabilities, greedy decoding may fail to explore alternative paths.</li>
    </ul>
  </li>
</ol>

<hr />

<h3 id="comparison-with-other-decoding-methods"><strong>Comparison with Other Decoding Methods</strong></h3>
<p>| <strong>Method</strong>          | <strong>Description</strong>                                             | <strong>Advantages</strong>                     | <strong>Disadvantages</strong>                  |
|———————|————————————————————-|————————————|————————————|
| <strong>Greedy Decoding</strong> | Selects the token with the highest probability at each step | Fast and deterministic             | Misses globally optimal solutions  |
| <strong>Beam Search</strong>     | Explores multiple paths (beams) to find the most likely sequence | Balances exploration and exploitation | Computationally expensive          |
| <strong>Sampling</strong>        | Selects tokens based on probability distribution (not just max) | Adds diversity to output           | Can generate incoherent sequences  |
| <strong>Top-k Sampling</strong>  | Samples from the top-k most probable tokens                 | Balances diversity and coherence   | Still somewhat stochastic          |
| <strong>Top-p (Nucleus)</strong> | Samples tokens from a cumulative probability threshold      | Highly flexible and dynamic        | Requires careful tuning            |</p>

<hr />

<h3 id="applications-of-greedy-decoding"><strong>Applications of Greedy Decoding</strong></h3>
<ul>
  <li><strong>Quick and Deterministic Generation</strong>:
    <ul>
      <li>Suitable for tasks where generating <strong>one correct answer</strong> is sufficient, such as:
        <ul>
          <li>Machine translation (e.g., Google Translate).</li>
          <li>Question answering (e.g., FAQ bots).</li>
          <li>Factual text generation.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Baselines for Comparison</strong>:
    <ul>
      <li>Greedy decoding is often used as a <strong>benchmark</strong> for evaluating the performance of more sophisticated decoding methods like beam search or sampling.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="example-of-greedy-decoding"><strong>Example of Greedy Decoding</strong></h3>
<h4 id="input-prompt">Input Prompt:</h4>
<p><em>“Translate English to French: The cat is on the mat.”</em></p>

<h4 id="model-predictions-per-step">Model Predictions (per step):</h4>
<ol>
  <li><strong>Step 1</strong>: [“Le” (0.8), “Un” (0.1), “La” (0.05)] → Greedy Decoding selects <strong>“Le”</strong>.</li>
  <li><strong>Step 2</strong>: [“chat” (0.9), “chien” (0.05), “oiseau” (0.02)] → Greedy Decoding selects <strong>“chat”</strong>.</li>
  <li><strong>Step 3</strong>: [“est” (0.85), “sont” (0.1), “était” (0.05)] → Greedy Decoding selects <strong>“est”</strong>.</li>
  <li><strong>Step 4</strong>: [“sur” (0.95), “dans” (0.02), “près” (0.01)] → Greedy Decoding selects <strong>“sur”</strong>.</li>
  <li><strong>Step 5</strong>: [“le” (0.9), “un” (0.05), “la” (0.04)] → Greedy Decoding selects <strong>“le”</strong>.</li>
  <li><strong>Step 6</strong>: [“tapis” (0.88), “sol” (0.05), “chaise” (0.02)] → Greedy Decoding selects <strong>“tapis”</strong>.</li>
</ol>

<h4 id="output">Output:</h4>
<p><em>“Le chat est sur le tapis.”</em></p>

<hr />

<h3 id="when-to-use-greedy-decoding"><strong>When to Use Greedy Decoding</strong></h3>
<ul>
  <li>Use greedy decoding when:
    <ul>
      <li><strong>Speed</strong> is critical, and the task does not require exploration of alternative outputs.</li>
      <li>The task demands a <strong>single correct answer</strong>, and alternative outputs are unlikely to be beneficial (e.g., translation, extractive summarization).</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>Greedy decoding is a simple and efficient decoding strategy that works well for deterministic tasks but may fall short for tasks requiring creativity, diversity, or long-term planning. Understanding its strengths and limitations is essential for choosing the right decoding strategy based on the task’s requirements.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Greedy Decoding is a text generation technique used in Natural Language Processing (NLP), particularly with models like GPT, T5, or other transformer-based models, to generate output token by token. It is one of the simplest decoding strategies and focuses on selecting the most likely next token at each step.]]></summary></entry><entry><title type="html">Understanding Zero-shot, One-shot, and Few-shot Inference in Machine Learning</title><link href="http://localhost:4000/2024/11/26/understanding-zero-shot-one-shot-and-few-shot-inference-in-machine-learning.html" rel="alternate" type="text/html" title="Understanding Zero-shot, One-shot, and Few-shot Inference in Machine Learning" /><published>2024-11-26T22:40:00-05:00</published><updated>2024-11-26T22:40:00-05:00</updated><id>http://localhost:4000/2024/11/26/understanding-zero-shot-one-shot-and-few-shot-inference-in-machine-learning</id><content type="html" xml:base="http://localhost:4000/2024/11/26/understanding-zero-shot-one-shot-and-few-shot-inference-in-machine-learning.html"><![CDATA[<p><strong>Title: Understanding Zero-shot, One-shot, and Few-shot Inference in Machine Learning</strong></p>

<h3 id="introduction">Introduction</h3>
<p>In modern machine learning, especially with the rise of <strong>large language models (LLMs)</strong> and other pretrained models, <strong>zero-shot</strong>, <strong>one-shot</strong>, and <strong>few-shot inference</strong> are pivotal paradigms that showcase a model’s ability to generalize to tasks with little or no labeled data. These approaches reduce the need for extensive fine-tuning and data labeling, making them powerful tools for solving a variety of problems efficiently. This article explains each of these paradigms, highlights their applications, and compares their strengths and challenges.</p>

<hr />

<h3 id="1-zero-shot-inference"><strong>1. Zero-shot Inference</strong></h3>
<p><strong>Definition</strong>: Zero-shot inference allows a model to perform tasks it has not been explicitly trained on. It uses the knowledge gained during pretraining to generalize to unseen tasks without needing any labeled examples.</p>

<h4 id="key-characteristics"><strong>Key Characteristics</strong>:</h4>
<ul>
  <li><strong>No Task-specific Training</strong>: The model has not seen any examples of the specific task during training.</li>
  <li><strong>Natural Language Prompts</strong>: Tasks are formulated using natural language instructions.</li>
  <li><strong>Applications</strong>:
    <ul>
      <li>Sentiment analysis (e.g., “Classify this review as Positive or Negative”).</li>
      <li>Language translation (e.g., “Translate: Hello to French”).</li>
      <li>Text summarization and topic detection.</li>
    </ul>
  </li>
  <li><strong>Advantages</strong>:
    <ul>
      <li>Eliminates the need for labeled data.</li>
      <li>Cost-effective and scalable for diverse tasks.</li>
    </ul>
  </li>
  <li><strong>Challenges</strong>:
    <ul>
      <li>Performance depends on the diversity of pretraining data.</li>
      <li>Prompt design significantly influences results.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="2-one-shot-inference"><strong>2. One-shot Inference</strong></h3>
<p><strong>Definition</strong>: In one-shot inference, a model performs a task by learning from <strong>one labeled example</strong> or demonstration.</p>

<h4 id="key-characteristics-1"><strong>Key Characteristics</strong>:</h4>
<ul>
  <li><strong>Single Example Provided</strong>: The model uses one labeled example to guide its predictions.</li>
  <li><strong>Applications</strong>:
    <ul>
      <li>Text classification (e.g., “Classify: ‘I loved the movie!’ -&gt; Positive”).</li>
      <li>Language translation with one example (e.g., “Translate: ‘Hello -&gt; Bonjour’.”).</li>
      <li>Personalized assistants adapting to user preferences after a single interaction.</li>
    </ul>
  </li>
  <li><strong>Advantages</strong>:
    <ul>
      <li>Minimal data requirement for a new task.</li>
      <li>Enables faster task adaptation compared to fine-tuning.</li>
    </ul>
  </li>
  <li><strong>Challenges</strong>:
    <ul>
      <li>Performance heavily depends on the quality and relevance of the single example.</li>
      <li>Struggles with generalization in complex tasks.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="3-few-shot-inference"><strong>3. Few-shot Inference</strong></h3>
<p><strong>Definition</strong>: Few-shot inference extends one-shot inference by providing <strong>a small number of labeled examples</strong> (typically 2–10) to guide the model in solving a task.</p>

<h4 id="key-characteristics-2"><strong>Key Characteristics</strong>:</h4>
<ul>
  <li><strong>Small Labeled Dataset</strong>: A few examples provide context for the model to infer patterns.</li>
  <li><strong>Applications</strong>:
    <ul>
      <li>Text classification (e.g., “Classify: ‘The weather is great!’ -&gt; Positive”).</li>
      <li>Speech recognition with limited examples for speaker adaptation.</li>
      <li>Rare medical diagnosis using minimal labeled data.</li>
    </ul>
  </li>
  <li><strong>Advantages</strong>:
    <ul>
      <li>Balances generalization and task adaptability.</li>
      <li>Suitable for low-resource scenarios.</li>
    </ul>
  </li>
  <li><strong>Challenges</strong>:
    <ul>
      <li>Model performance is sensitive to the diversity and quality of examples.</li>
      <li>Requires careful prompt design to maximize results.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="comparison-of-zero-shot-one-shot-and-few-shot-inference"><strong>Comparison of Zero-shot, One-shot, and Few-shot Inference</strong></h3>
<p>| <strong>Aspect</strong>             | <strong>Zero-shot Inference</strong>          | <strong>One-shot Inference</strong>          | <strong>Few-shot Inference</strong>         |
|————————|———————————-|———————————|——————————–|
| <strong>Examples Provided</strong>  | None                            | One labeled example             | Few labeled examples (2–10)   |
| <strong>Dependency</strong>         | Relies entirely on pretraining  | Uses pretraining + one example  | Relies on pretraining + multiple examples |
| <strong>Performance</strong>        | Less accurate for complex tasks | Better than zero-shot           | More reliable and generalizable |
| <strong>Applications</strong>       | General-purpose tasks           | Task-specific but minimal data  | Complex tasks with limited data |</p>

<hr />

<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>The paradigms of zero-shot, one-shot, and few-shot inference reflect the remarkable adaptability of pretrained models. These approaches are particularly valuable in situations where labeled data is scarce or unavailable. While zero-shot inference relies entirely on the model’s pretraining, one-shot and few-shot inference leverage minimal labeled examples to achieve better task-specific performance. With careful prompt engineering and leveraging powerful models like GPT-3 or T5, these methods have become indispensable in modern AI workflows, from text classification and translation to speech recognition and medical diagnostics.</p>

<p>These paradigms not only highlight the advancements in machine learning but also showcase how models can generalize knowledge to solve diverse problems efficiently.</p>

<hr />]]></content><author><name></name></author><summary type="html"><![CDATA[Title: Understanding Zero-shot, One-shot, and Few-shot Inference in Machine Learning]]></summary></entry><entry><title type="html">Why Transformers Outperform RNNs</title><link href="http://localhost:4000/2024/11/26/why-transformers-outperform-rnns.html" rel="alternate" type="text/html" title="Why Transformers Outperform RNNs" /><published>2024-11-26T22:03:00-05:00</published><updated>2024-11-26T22:03:00-05:00</updated><id>http://localhost:4000/2024/11/26/why-transformers-outperform-rnns</id><content type="html" xml:base="http://localhost:4000/2024/11/26/why-transformers-outperform-rnns.html"><![CDATA[<p>Both <strong>RNNs (Recurrent Neural Networks)</strong> and <strong>Transformers</strong> can use attention mechanisms, but there are fundamental differences in how they work and why Transformers are generally more effective. Here’s an in-depth comparison:</p>

<hr />

<h3 id="1-rnn-with-attention"><strong>1. RNN with Attention</strong></h3>
<ul>
  <li><strong>Architecture</strong>:
    <ul>
      <li>RNNs process input sequentially, one token at a time. This sequential nature makes RNNs inherently dependent on previous states to understand the context.</li>
      <li>The attention mechanism in RNNs was introduced to improve their ability to focus on relevant parts of the input sequence when generating output.</li>
    </ul>
  </li>
  <li><strong>How Attention Works in RNNs</strong>:
    <ul>
      <li>At each decoding step, attention computes a weighted sum of all encoder hidden states.</li>
      <li>These weights determine the importance of each input token based on its relevance to the current decoding step.</li>
    </ul>
  </li>
  <li><strong>Challenges</strong>:
    <ul>
      <li><strong>Sequential Processing</strong>: RNNs process tokens sequentially, which limits parallelization during training and inference.</li>
      <li><strong>Vanishing/Exploding Gradients</strong>: Long dependencies in sequences can degrade performance, even with attention.</li>
      <li><strong>Inefficiency</strong>: Attention improves performance but does not eliminate the bottleneck caused by sequential processing.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="2-transformers-with-attention"><strong>2. Transformers with Attention</strong></h3>
<ul>
  <li><strong>Architecture</strong>:
    <ul>
      <li>Transformers are built entirely on the attention mechanism, specifically <strong>self-attention</strong>, without relying on recurrence or convolution.</li>
      <li>Self-attention allows each token to directly interact with every other token in the sequence.</li>
    </ul>
  </li>
  <li><strong>How Attention Works in Transformers</strong>:
    <ul>
      <li><strong>Self-Attention</strong>: Computes the relationship between all tokens in the input sequence simultaneously.</li>
      <li><strong>Multi-Head Attention</strong>: Divides attention into multiple heads, enabling the model to learn different relationships in parallel.</li>
      <li>Transformers use positional encodings to incorporate order information since they lack the inherent sequential structure of RNNs.</li>
    </ul>
  </li>
  <li><strong>Advantages</strong>:
    <ul>
      <li><strong>Parallelization</strong>: Transformers process all tokens simultaneously, leading to much faster training compared to sequential RNNs.</li>
      <li><strong>Global Context</strong>: Each token can directly attend to every other token, capturing long-range dependencies effectively.</li>
      <li><strong>Scalability</strong>: Transformers scale better with larger datasets and models, as seen with architectures like GPT, BERT, and T5.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="key-differences"><strong>Key Differences</strong></h3>
<p>| Feature                 | RNN with Attention                                | Transformers                                       |
|————————-|————————————————–|————————————————–|
| <strong>Processing</strong>          | Sequential (token-by-token).                     | Parallel (all tokens processed at once).         |
| <strong>Core Mechanism</strong>      | Combines sequential recurrence with attention.   | Entirely attention-based (no recurrence).        |
| <strong>Efficiency</strong>          | Slower due to sequential nature.                 | Highly efficient due to parallelization.         |
| <strong>Dependency Modeling</strong> | Limited for long-range dependencies.             | Excellent at modeling long-range dependencies.   |
| <strong>Scalability</strong>         | Struggles with very large datasets or models.    | Scales well with more data and larger models.    |
| <strong>Order Sensitivity</strong>   | Captures order naturally through recurrence.     | Requires positional encoding to represent order. |</p>

<hr />

<h3 id="why-transformers-outperform-rnns"><strong>Why Transformers Outperform RNNs</strong></h3>
<ol>
  <li><strong>Better Parallelization</strong>: RNNs process sequences one token at a time, whereas Transformers process all tokens simultaneously, drastically improving computational efficiency.</li>
  <li><strong>Superior Long-Range Dependencies</strong>: RNNs struggle to retain context over long sequences, even with attention, due to the vanishing gradient problem. Transformers, with their global self-attention mechanism, excel in this area.</li>
  <li><strong>Scalability</strong>: Transformers handle larger datasets and deeper models better than RNNs, enabling breakthroughs in large-scale pretraining (e.g., GPT, BERT).</li>
  <li><strong>Training Speed</strong>: Transformers are faster to train because they avoid the sequential bottleneck of RNNs.</li>
</ol>

<hr />

<h3 id="when-rnns-may-still-be-useful"><strong>When RNNs May Still Be Useful</strong></h3>
<p>Despite the dominance of Transformers, RNNs (and their variants like LSTMs/GRUs) can still be useful for:</p>
<ul>
  <li>Low-resource environments where computational efficiency is critical.</li>
  <li>Sequential data where strict order is paramount, and simplicity is preferred.</li>
</ul>

<hr />

<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>While both RNNs with attention and Transformers use attention mechanisms, Transformers fundamentally reimagine how attention is applied, enabling unparalleled performance in tasks involving long sequences and large datasets. This paradigm shift has made Transformers the backbone of modern NLP.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Both RNNs (Recurrent Neural Networks) and Transformers can use attention mechanisms, but there are fundamental differences in how they work and why Transformers are generally more effective. Here’s an in-depth comparison:]]></summary></entry></feed>